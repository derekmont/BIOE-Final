{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmvah-s2OJyz",
    "outputId": "f8b6752e-317e-4f96-9726-bb35e6042ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_pruning in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch_pruning) (1.24.1)\n",
      "Requirement already satisfied: torch in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch_pruning) (2.2.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (2024.3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (4.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from torch->torch_pruning) (3.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from jinja2->torch->torch_pruning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\derek\\miniconda3\\envs\\cs4347\\lib\\site-packages (from sympy->torch->torch_pruning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_pruning\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch_pruning as tp\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLyS3QWWOZyg",
    "outputId": "7771b0ef-617d-4b82-d372-3cb6e86447fe"
   },
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features, 9)\n",
    "example_inputs = torch.randn(1, 3, 224, 224)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rPovri1PDSP",
    "outputId": "3ca44c7f-4794-41a6-9387-906a88fefe8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpBP0cthPFpN",
    "outputId": "c8a03ed4-27f5-430e-b24a-cad4509e17cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your pruning percentage for this test is 90.0 %.\n"
     ]
    }
   ],
   "source": [
    "# List of values\n",
    "ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "# Get a random value from the list\n",
    "pruning_ratio = random.choice(ratios)\n",
    "pruning_percentage = float(pruning_ratio * 100)\n",
    "\n",
    "print(f\"Your pruning percentage for this test is {pruning_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4QiQCqfNPjAk"
   },
   "outputs": [],
   "source": [
    "# 1. Importance criterion\n",
    "imp = tp.importance.GroupTaylorImportance() # or GroupNormImportance(p=2), GroupHessianImportance(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKJv4O98Psmm"
   },
   "outputs": [],
   "source": [
    "# 2. Ignore Output Layer for Pruning\n",
    "ignored_layers = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 9:\n",
    "        ignored_layers.append(m) # DO NOT prune the final classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RaWwiPthPwnv"
   },
   "outputs": [],
   "source": [
    "# 3. Create Meta Pruner Model\n",
    "pruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n",
    "    model,\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    pruning_ratio=pruning_ratio, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
    "    ignored_layers=ignored_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9ZE5eNeP3SE",
    "outputId": "805cffb1-8ef1-4aa6-e1c7-7f5ec11d3391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Params in Millions: 11.181129\n",
      "\n",
      "Base MACs in Millions: 1821.669385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Print the base number of parameters and MACs\n",
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(f\"Base Params in Millions: {base_nparams/1e6}\\n\")\n",
    "print(f\"Base MACs in Millions: {base_macs/1e6}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "InSzzAXgP6sH"
   },
   "outputs": [],
   "source": [
    "# 5. Prune\n",
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "if isinstance(imp, tp.importance.GroupTaylorImportance):\n",
    "    outputs = model(example_inputs)\n",
    "    target = torch.randint(0, 9, (1,))  # 9 classes for classification\n",
    "    loss = loss_function(outputs, target)\n",
    "    loss.backward() # before pruner.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5vguHZOQDnM",
    "outputId": "e7af3a16-a32a-4771-a1af-c20cbe121a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Params in Millions: 0.111046\n",
      "\n",
      "Pruned MACs in Millions: 27.467222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Print the pruned model number of parameters and MACs\n",
    "pruner.step()\n",
    "macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(f\"Pruned Params in Millions: {nparams/1e6}\\n\")\n",
    "print(f\"Pruned MACs in Millions: {macs/1e6}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "e6kAK6ytQRN2"
   },
   "outputs": [],
   "source": [
    "# 7. Set up training and testing directories\n",
    "train_dir = \"train\"\n",
    "val_dir = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Perform Data Augmentation on train and test data\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ColorJitter(brightness=0.1),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Prepare Dataloaders\n",
    "train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transforms_val)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=12, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #1] Loss: 0.1821 Acc: 18.7948% Time: 34.5810s\n",
      "\n",
      "Epoch 1 running\n",
      "[Train #2] Loss: 0.1707 Acc: 30.4161% Time: 69.0289s\n",
      "\n",
      "Epoch 2 running\n",
      "[Train #3] Loss: 0.1625 Acc: 33.7159% Time: 105.2924s\n",
      "\n",
      "Epoch 3 running\n",
      "[Train #4] Loss: 0.1535 Acc: 39.7418% Time: 138.5668s\n",
      "\n",
      "Epoch 4 running\n",
      "[Train #5] Loss: 0.1487 Acc: 40.3156% Time: 175.0220s\n",
      "\n",
      "Epoch 5 running\n",
      "[Train #6] Loss: 0.1401 Acc: 47.6327% Time: 211.7935s\n",
      "\n",
      "Epoch 6 running\n",
      "[Train #7] Loss: 0.1381 Acc: 45.9110% Time: 244.4295s\n",
      "\n",
      "Epoch 7 running\n",
      "[Train #8] Loss: 0.1313 Acc: 50.2152% Time: 281.2575s\n",
      "\n",
      "Epoch 8 running\n",
      "[Train #9] Loss: 0.1260 Acc: 51.2195% Time: 314.7184s\n",
      "\n",
      "Epoch 9 running\n",
      "[Train #10] Loss: 0.1219 Acc: 52.9412% Time: 353.8662s\n",
      "\n",
      "Epoch 10 running\n",
      "[Train #11] Loss: 0.1225 Acc: 51.2195% Time: 388.7078s\n",
      "\n",
      "Epoch 11 running\n",
      "[Train #12] Loss: 0.1156 Acc: 55.0933% Time: 426.9842s\n",
      "\n",
      "Epoch 12 running\n",
      "[Train #13] Loss: 0.1136 Acc: 56.0976% Time: 463.5556s\n",
      "\n",
      "Epoch 13 running\n",
      "[Train #14] Loss: 0.1106 Acc: 56.3845% Time: 496.3715s\n",
      "\n",
      "Epoch 14 running\n",
      "[Train #15] Loss: 0.1054 Acc: 57.6758% Time: 533.5025s\n",
      "\n",
      "Test Loss: 0.0990 Acc: 57.4586% Time: 539.5026s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "train_loss=[]\n",
    "train_accuary=[]\n",
    "val_loss=[]\n",
    "val_accuary=[]\n",
    "\n",
    "num_epochs = 15   #(set no of epochs)\n",
    "start_time = time.time() #(for showing time)\n",
    "\n",
    "for epoch in range(num_epochs): #(loop for every epoch)\n",
    "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    #(training model)\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0 \n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device) \n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    # Append result\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuary.append(epoch_acc)\n",
    "    # Print progress\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s\\n'.format(epoch+1, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    \n",
    "# Evaluate Model on Test Data\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in val_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "    epoch_loss = running_loss / len(val_dataset)\n",
    "    epoch_acc = running_corrects / len(val_dataset) * 100.\n",
    "    # Append result\n",
    "    val_loss.append(epoch_loss)\n",
    "    val_accuary.append(epoch_acc)\n",
    "    # Print progress\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s\\n'.format(epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
